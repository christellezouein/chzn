---
layout: page
title:  "ComDaAn: Community Data Analytics"
subtitle: "An overview of the project"
date:   2020-01-07
categories: ["general"]
---

Faced with the growing number of tools developers use to write and distribute code and the data footprint these leave behind, we decided to have a closer look. And so, ComDaAn analyses said footprint to offer an insight into the inner workings of open source communities and teams of developers.

This article will cover community data analysis in the context of open source development and free software. More specifically, it will seek to introduce ComDaAn and explain the newest additions.

## A little bit of history

Paul Adams is a developer renown for his work in the field of free software and his many contributions to the KDE FOSS community. Before retiring from KDE, Adams provided the community with a service in the form of community data visualization using git repositories. To ensure the continuity of the service, Kevin Ottens, libre software craftsman and developer at enioka Haute Couture, decided to take over.

And so, ComDaAn took form as a way of modernizing Paul Adams&#39; scripts while staying true to his vision. That, later on, turned into a complete rewrite with the purpose of creating a solid base for data analytics in general. The project then became a suite of tools to study and analyze community data.

## Features

ComDaAn became what it is today thanks to the common effort of multiple developers. It has many features most of which will be explained in what follows.

### Supported data sources

To analyze communities, ComDaAn uses git repositories, mailing lists and GitLab issues.

#### Git Repositories

Perhaps the most intuitive data source to consider would be git repositories.

Git repositories are a way to store files as well as track the changes that have been made to them. Git is a tool designed to coordinate work between programmers and is currently the one most commonly used by both free software and proprietary software communities alike. So, analyzing their git repositories and thus the products they put forth would be the most direct way to study these communities.

This was the starting point for ComDaAn.

#### Mailing Lists

Mailing lists are a sort of discussion lists or forums where internet user can communicate and discuss certain subjects. Because of the advantages they present over other means of communications, such as the possibility to work offline, that of signing one&#39;s emails via GPG or even using a mail client&#39;s filtering features, they are commonly used in open source communities

Therefore, analyzing the public mailing lists of an open source community, or even the private mailing lists of a team of developers, offers an insight into the discussion within them as well as their readiness for discussion with both users and developers. It thus seemed appropriate to add this data source to ComDaAn to establish a more complete profile of the community or team studied.

#### GitLab Issues

Some Git repository managers like GitLab or GitHub offer an issue tracking system (ITS) that manages and maintains lists of issues. Issues consist of work needed to improve a project. Popular amongst developer teams and communities, ITSs have become a tool for software maintenance. Analyzing them therefore allows the scrutiny of this aspect of a project.

Moreover, certain actors of software communities still went unnoticed even with two data sources. Analyzing the issues of a project helps to overcome this problem since it focuses on the lesser known members of the community: those who report bugs (the reporters) and those who discuss them (the commenters).

For these reasons, ComDaAn needed to be expanded to include the analysis and fetching of GitLab issues.

### Types of Analyses

There are 5 types of analyses in ComDaAn that a user can perform on the supported data sources: activity, size, network, centrality and response time.

In what follows, the team or community mentioned is formed by the authors of the entries and the project by the data source or sources submitted for analysis. The duration of the project thus becomes equal to the duration of all the entries combined. In addition to that, the results obtained represent the active members of the entity in question and not all the entity.

#### Activity

The activity analysis can be seen as a tool that is used to visualize the activity of the members of a community or a team, week by week, for the duration of a certain project. And so, thanks to this type of analysis, it becomes possible to easily identify who has been the most active as well as who hasn&#39;t. Indeed, the activity visualization consists of a list of the names of the authors  of commits, messages and/or issues and their activity by week for every week of the duration of said project.

To illustrate let's consider the following example:

```html
{% include activity.html %}
```

Thanks to the above visualization, we can examine the authors that have contributed to the project and the frequency at which they have. And the darker the color, the more active the author has been during the corresponding week.

#### Size

The size analysis can be seen as a tool that is used to plot the variation of a community&#39;s size and activity over the duration of a project. The analysis produces a scatterplot that, thanks to a LOWESS regression, turns into two curves, one representing the number of authors in a community as a function of time and one representing the number of entries in the corresponding project as a function of time.

The resulting visualization would resemble the following:

\&lt;teamsize.html\&gt;

With such a team/community size analysis, it becomes possible to reveal certain patterns that would otherwise have gone unnoticed. For example, an analysis of this type of a mailing list, coupled with that of git repositories of the same team or community, could offer a deeper insight into it by allowing us for example to explore the causality between the growth of a community  and the communication between its developers.

#### Network

The network analysis is a tool to show the relationships between the different members of a team or community as well as its structure.

To create the graph representing said structure and calculate the centrality of each node or author, we proceed differently for each data source:

- For git repositories, we mainly consider the changes an author made to a set of files and the more said author has modified files a lot of others have modified, or in other words more &quot;popular&quot; files, the larger their weight.
- For mailing lists, we mainly use the references in a message. And thus, the more a sender has been referenced by different senders, the larger their weight.
- For GitLab issues, we rely on the the discussion surrounding the issues of a project which entails that the more an author reports bugs and comments on discussion threads, the larger their weight.

An example of a network visualization would be:

\&lt;network.html\&gt;

#### Centrality

Where a network analysis shows the centrality of the different members of a team or a community, a centrality analysis shows the variation of that of an individual author over time. In it, the centrality of an author is calculated similarly to how it is in the network analysis, but instead of considering the duration of the whole project, it considers a smaller interval and calculates the centrality of the author over it. It then repeats the computation over the course of said project. Thus, this type of visualizations displays the variation of the centrality of a member over time. It also displays the activity variation of the author over time and that of size of the community over the same time.

Instead of studying the entity in question at the community or team scale, the centrality analysis allows us to study each member at the author scale and their impact on the team or community.

Indeed:

\&lt;centrality.html\&gt;

#### Response time

Essentially, issues are the support that the creators of a certain software offer to its users. So, the study of the response time of a team to reported bugs and issues offers an insight into the maintenance of said software and the dedication of the team to technical support.

This analysis calculates, on one hand, the duration between the creation of the issue and the start of the discussion around it to plot the variation of the response time over time, and on the other the rate of unanswered issues at each point in time.

More specifically, we obtain a figure, where the curve representing the variation over time of the response time to issues and a bar chart representing the number of unanswered issues.

For example:

\&lt;Response.html\&gt;

We can thus get an idea of the dedication of a community or team to the success of their products after deployment. Subsequently such a visualization can for example help in the choice of new tools to adopt.

### Interface

The ComDaAn user interface has been designed to be efficient and easy to use. It is a hybrid interface and is made up of a script to collect the data sources from the GitLab API and a python library for parsing, analyzing and displaying data.

The library consists of three functions for the parsing of the three different data sources, of five functions for the five different analyses, and of one function to display the results. It mainly uses data frame objects from the python pandas library, making it more universal. It also allows the user to modify these data frames according to their needs as well as to choose the columns they want to use for their analysis. In fact, to use the library, we must specify the data set as well as the columns to be considered when calling each analysis function.

To better illustrate this point, let&#39;s consider the following code snippet:

```
# script.py
import comdaan as cd

commits = cd.parse_repositories('~/path_to_repositories')
activity = cd.activity(commits, 'id', 'author_email', 'date')
cd.display(activity)
```

Here, we want to perform an activity analysis of some git repositories located at a certain path from the root. We first start by calling the parsing function that corresponds to our data source. That function returns a data frame of the different entries. Then, we call the activity analysis function on the data frame and specify the columns to be considered. Finally, we display our result with the display function. However, to have the authors&#39; email addresses in our final DataFrame instead of their names, we enter the name of the author email column where the function expects the author names. The result then displays the activity per week for individuals whose emails are those found in the dataset.

Indeed:

\&lt;activity\_email\_addresses.html\&gt;

Moreover, the display function offers many options. It can receive as a parameter a heterogenous list of elements and displays them differently according to their types. It can also receive a simple pandas data frame and display it. Additionally, to better compare two or more results of the same object type, it is possible to display them on the same figure with the same axes. Examining them would have us look at one figure with different plots instead of repeatedly switch between tabs.

 To better illustrate, let&#39;s consider this time the following code snippet:

```
# script.py
import comdaan as cd

commits = cd.parse_repositories('~/path_to_data')
issues = cd.parse_issues('~/path_to_data')
commits_ts = cd.teamsize(commits, 'id', 'author_name', 'date')
issues_ts = cd.teamsize(issues, 'id', 'author', 'created_at')
cd.display([commits_ts, issues_ts])
```

Here, we decided to use data from different sources but apply the same analysis to them and then display them at once. The two different figures are then overlayed.

Like so:

\&lt;overlaying\_teamsize.html\&gt;

Finally, thanks to the separation of the different stages of the ComDaAn process, it is possible to avoid potential redundancies. Indeed, the parsing which is the most time consuming step of the whole process is done once per data source where it used to be done once for each analysis being called by each script separately, and the display is optimized.

## And now...

During my four-month internship at enioka, I worked on ComDaAn and more specifically on optimizing the code performance wise, on adding mailing lists and issues as additional data sources, on smoothing methods for the different curves displayed, and finally on the design and programming of the interface.

The ComDaAn project has evolved over time thanks to the work and dedication of many contributors. In the same manner, it will continue to evolve and find new ways to serve community data analytics as well as the open source community.
